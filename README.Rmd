---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<a href={https://github.com/Ehyaei/RTLNotes}><img src="images/counterfactualsvg.svg" alt="RTLNotes logo" align="right" width="160" style="padding: 0 15px; float: right;"/>

# Robustness implies Fairness in Causal Algorithmic Recourse

This project implements the paper "Robustness implies Fairness in Casual Algorithmic Recourse" using the R language. 

This paper explores the concept of fairness and robustness in causal algorithmic recourse, whereby the challenges of jointly achieving adversarially robust and individually fair recourse are examined.
A protected group variable is defined as a pseudometric function, and it is shown that fairness is a special case of robustness when the perturbation radius is zero. 
Finally, we introduce the fair robust recourse problem to achieve both desirable properties and show how it can be satisfied both theoretically and empirically.

<img src="images/19: SCM:ANM__label:LIN__w:aware__b:0.svg" width="45%" align="left" />
<img src="images/64: SCM:ANM__label:NLM__w:aware__b:2.svg" width="45%" align="right" />
<img src="images/117: SCM:ANM__label:NLM__w:unaware__b:2_h:GBM_l:unaware_delta:1.svg" width="45%" align="left" />
<img src="images/113: SCM:ANM__label:LIN__w:unaware__b:0_h:GBM_l:unaware_delta:1.svg" width="45%" align="right" />
